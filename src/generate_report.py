"""Generate training report from model results"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import json
from datetime import datetime
from pathlib import Path


def load_json(filepath):
    """Load JSON file"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)


def format_number(num, decimals=2):
    """Format large numbers"""
    if num >= 1e12:
        return f"{num/1e12:.{decimals}f}ì¡°"
    elif num >= 1e8:
        return f"{num/1e8:.{decimals}f}ì–µ"
    elif num >= 1e4:
        return f"{num/1e4:.{decimals}f}ë§Œ"
    else:
        return f"{num:,.{decimals}f}"


def generate_report(models_dir='models', output_path='TRAINING_REPORT.md'):
    """Generate training report markdown"""
    
    # Load metrics
    metrics_path = os.path.join(models_dir, 'metrics.json')
    feature_importance_path = os.path.join(models_dir, 'feature_importance.json')
    
    if not os.path.exists(metrics_path):
        print(f"Error: Metrics file not found at {metrics_path}")
        return
    
    metrics = load_json(metrics_path)
    feature_importance = load_json(feature_importance_path) if os.path.exists(feature_importance_path) else {}
    
    # Generate report
    report = f"""# ë©”ì´í”ŒìŠ¤í† ë¦¬ ì•„ì´í…œ ì‹œì„¸ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ ë¦¬í¬íŠ¸

**ìƒì„± ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“Š ì‹¤í–‰ ìš”ì•½

ì´ ë¦¬í¬íŠ¸ëŠ” MySQL ë°ì´í„°ë² ì´ìŠ¤ì˜ ëª¨ë“  ê±°ë˜ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ëœ ì•„ì´í…œ ì‹œì„¸ ì˜ˆì¸¡ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì •ë¦¬í•©ë‹ˆë‹¤.

### ëª¨ë¸ ì •ë³´
- **ëª¨ë¸ íƒ€ì…**: Random Forest Regressor
- **ë°ì´í„°ì…‹**: ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ë°ì´í„° (ì œí•œ ì—†ìŒ)
- **ë°ì´í„° ë¶„í• **: Train 70%, Validation 10%, Test 20%
- **ë¶„í•  ë°©ì‹**: ì‹œê°„ ìˆœì„œ ê¸°ë°˜ ë¶„í•  (ìµœê·¼ ë°ì´í„°ë¥¼ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ì‚¬ìš©)

---

## ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ

### Train Set (í›ˆë ¨ ë°ì´í„°)

| ì§€í‘œ | ê°’ | ì„¤ëª… |
|------|-----|------|
| **RMSE** | {metrics.get('train_rmse', 0):,.2f} | {format_number(metrics.get('train_rmse', 0))} |
| **MAE** | {metrics.get('train_mae', 0):,.2f} | {format_number(metrics.get('train_mae', 0))} |
| **RÂ² Score** | {metrics.get('train_r2', 0):.4f} | {metrics.get('train_r2', 0)*100:.2f}% ì„¤ëª…ë ¥ |
| **MAPE** | {metrics.get('train_mape', 0):.2f}% | í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨ |

### Validation Set (ê²€ì¦ ë°ì´í„°)

| ì§€í‘œ | ê°’ | ì„¤ëª… |
|------|-----|------|
| **RMSE** | {metrics.get('val_rmse', 0):,.2f} | {format_number(metrics.get('val_rmse', 0))} |
| **MAE** | {metrics.get('val_mae', 0):,.2f} | {format_number(metrics.get('val_mae', 0))} |
| **RÂ² Score** | {metrics.get('val_r2', 0):.4f} | {metrics.get('val_r2', 0)*100:.2f}% ì„¤ëª…ë ¥ |
| **MAPE** | {metrics.get('val_mape', 0):.2f}% | í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨ |

### Test Set (í…ŒìŠ¤íŠ¸ ë°ì´í„°)

| ì§€í‘œ | ê°’ | ì„¤ëª… |
|------|-----|------|
| **RMSE** | {metrics.get('test_rmse', 0):,.2f} | {format_number(metrics.get('test_rmse', 0))} |
| **MAE** | {metrics.get('test_mae', 0):,.2f} | {format_number(metrics.get('test_mae', 0))} |
| **RÂ² Score** | {metrics.get('test_r2', 0):.4f} | {metrics.get('test_r2', 0)*100:.2f}% ì„¤ëª…ë ¥ |
| **MAPE** | {metrics.get('test_mape', 0):.2f}% | í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨ |

---

## ğŸ” ì„±ëŠ¥ ë¶„ì„

### 1. ëª¨ë¸ ì¼ë°˜í™” ì„±ëŠ¥

- **Train vs Test RÂ² ì°¨ì´**: {abs(metrics.get('train_r2', 0) - metrics.get('test_r2', 0)):.4f}
  - ì°¨ì´ê°€ ì‘ì„ìˆ˜ë¡ ê³¼ì í•©ì´ ì ìŠµë‹ˆë‹¤
  - ì°¨ì´ê°€ í¬ë©´ ê³¼ì í•© ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤

- **Train vs Test RMSE ë¹„ìœ¨**: {metrics.get('test_rmse', 1) / max(metrics.get('train_rmse', 1), 1):.2f}x
  - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ RMSEê°€ í›ˆë ¨ ì„¸íŠ¸ë³´ë‹¤ {metrics.get('test_rmse', 1) / max(metrics.get('train_rmse', 1), 1):.2f}ë°° ë†’ìŠµë‹ˆë‹¤

### 2. ì˜ˆì¸¡ ì •í™•ë„

- **í‰ê·  ì ˆëŒ€ ì˜¤ì°¨ (MAE)**: {format_number(metrics.get('test_mae', 0))}
  - í‰ê· ì ìœ¼ë¡œ ì˜ˆì¸¡ ê°€ê²©ê³¼ ì‹¤ì œ ê°€ê²©ì˜ ì°¨ì´ê°€ {format_number(metrics.get('test_mae', 0))} ì •ë„ì…ë‹ˆë‹¤

- **í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨ (MAPE)**: {metrics.get('test_mape', 0):.2f}%
  - ì˜ˆì¸¡ ì˜¤ì°¨ê°€ í‰ê· ì ìœ¼ë¡œ {metrics.get('test_mape', 0):.2f}% ìˆ˜ì¤€ì…ë‹ˆë‹¤

### 3. ëª¨ë¸ ì„¤ëª…ë ¥

- **RÂ² Score (Test)**: {metrics.get('test_r2', 0):.4f} ({metrics.get('test_r2', 0)*100:.2f}%)
  - ëª¨ë¸ì´ ê°€ê²© ë³€ë™ì˜ ì•½ {metrics.get('test_r2', 0)*100:.2f}%ë¥¼ ì„¤ëª…í•©ë‹ˆë‹¤
  - {'ë§¤ìš° ìš°ìˆ˜' if metrics.get('test_r2', 0) > 0.9 else 'ìš°ìˆ˜' if metrics.get('test_r2', 0) > 0.8 else 'ì–‘í˜¸' if metrics.get('test_r2', 0) > 0.7 else 'ë³´í†µ' if metrics.get('test_r2', 0) > 0.5 else 'ê°œì„  í•„ìš”'}í•œ ìˆ˜ì¤€ì…ë‹ˆë‹¤

---

## ğŸ¯ ì£¼ìš” íŠ¹ì§• ì¤‘ìš”ë„ (Top 20)

ëª¨ë¸ì´ ê°€ê²© ì˜ˆì¸¡ì— ì‚¬ìš©í•œ ì£¼ìš” íŠ¹ì§•ë“¤ì˜ ì¤‘ìš”ë„ ìˆœìœ„ì…ë‹ˆë‹¤:

"""
    
    # Add feature importance table
    if feature_importance:
        sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
        report += "| ìˆœìœ„ | íŠ¹ì§•ëª… | ì¤‘ìš”ë„ | ë¹„ìœ¨ |\n"
        report += "|------|--------|--------|------|\n"
        
        total_importance = sum(feature_importance.values())
        for i, (feature, importance) in enumerate(sorted_features[:20], 1):
            percentage = (importance / total_importance * 100) if total_importance > 0 else 0
            report += f"| {i} | `{feature}` | {importance:.6f} | {percentage:.2f}% |\n"
    else:
        report += "íŠ¹ì§• ì¤‘ìš”ë„ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
    
    report += f"""

---

## ğŸ’¡ ì£¼ìš” íŠ¹ì§• ë¶„ì„

"""
    
    if feature_importance:
        sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
        top_features = sorted_features[:10]
        
        report += "### ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì§• Top 10\n\n"
        for i, (feature, importance) in enumerate(top_features, 1):
            report += f"{i}. **{feature}**\n"
            report += f"   - ì¤‘ìš”ë„: {importance:.6f}\n"
            report += f"   - íŠ¹ì§• ì„¤ëª…: {get_feature_description(feature)}\n\n"
    
    report += f"""---

## ğŸ“ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­

### ëª¨ë¸ ì„±ëŠ¥ ìš”ì•½

1. **ì „ë°˜ì ì¸ ì„±ëŠ¥**: {'ë§¤ìš° ìš°ìˆ˜' if metrics.get('test_r2', 0) > 0.9 else 'ìš°ìˆ˜' if metrics.get('test_r2', 0) > 0.8 else 'ì–‘í˜¸' if metrics.get('test_r2', 0) > 0.7 else 'ë³´í†µ'}
   - RÂ² Scoreê°€ {metrics.get('test_r2', 0):.4f}ë¡œ ê°€ê²© ë³€ë™ì˜ ìƒë‹¹ ë¶€ë¶„ì„ ì˜ ì„¤ëª…í•©ë‹ˆë‹¤

2. **ì˜ˆì¸¡ ì •í™•ë„**: {'ë†’ìŒ' if metrics.get('test_mape', 100) < 10 else 'ë³´í†µ' if metrics.get('test_mape', 100) < 20 else 'ë‚®ìŒ'}
   - MAPEê°€ {metrics.get('test_mape', 0):.2f}%ë¡œ {'ë§¤ìš°' if metrics.get('test_mape', 0) < 5 else 'ì ì ˆí•œ' if metrics.get('test_mape', 0) < 10 else 'ê°œì„ ì´ í•„ìš”í•œ'} ìˆ˜ì¤€ì…ë‹ˆë‹¤

3. **ê³¼ì í•© ì—¬ë¶€**: {'ê³¼ì í•©ì´ ì ìŒ' if abs(metrics.get('train_r2', 0) - metrics.get('test_r2', 0)) < 0.1 else 'ê³¼ì í•© ê°€ëŠ¥ì„± ìˆìŒ'}
   - Train RÂ²ì™€ Test RÂ²ì˜ ì°¨ì´ê°€ {abs(metrics.get('train_r2', 0) - metrics.get('test_r2', 0)):.4f}ì…ë‹ˆë‹¤

### ê°œì„  ê¶Œì¥ì‚¬í•­

"""
    
    # Add recommendations based on metrics
    recommendations = []
    
    if abs(metrics.get('train_r2', 0) - metrics.get('test_r2', 0)) > 0.15:
        recommendations.append("- **ê³¼ì í•© ì™„í™”**: Train/Test ì„±ëŠ¥ ì°¨ì´ê°€ í½ë‹ˆë‹¤. ì •ê·œí™” ê°•í™”, ëª¨ë¸ ë³µì¡ë„ ê°ì†Œ, ë˜ëŠ” ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ ê³ ë ¤")
    
    if metrics.get('test_r2', 0) < 0.7:
        recommendations.append("- **ëª¨ë¸ ì„±ëŠ¥ ê°œì„ **: ë” ë§ì€ íŠ¹ì§• ì—”ì§€ë‹ˆì–´ë§, ë‹¤ë¥¸ ëª¨ë¸ ì‹œë„ (Gradient Boosting, XGBoost ë“±), í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ê³ ë ¤")
    
    if metrics.get('test_mape', 100) > 20:
        recommendations.append("- **ì˜ˆì¸¡ ì •í™•ë„ ê°œì„ **: ê°€ê²© ë²”ìœ„ê°€ ë„“ì–´ì„œ ì˜¤ì°¨ê°€ í½ë‹ˆë‹¤. ë¡œê·¸ ë³€í™˜, ê°€ê²© ë²”ìœ„ë³„ ëª¨ë¸ ë¶„ë¦¬, ì´ìƒì¹˜ ì²˜ë¦¬ ê³ ë ¤")
    
    if not recommendations:
        recommendations.append("- ëª¨ë¸ ì„±ëŠ¥ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤. í˜„ì¬ ì„¤ì •ì„ ìœ ì§€í•˜ê±°ë‚˜ ì¶”ê°€ ë°ì´í„°ë¡œ ì¬í›ˆë ¨ì„ ê³ ë ¤í•˜ì„¸ìš”")
        recommendations.append("- ë‹¤ì–‘í•œ ëª¨ë¸ íƒ€ì…ì„ ë¹„êµí•˜ì—¬ ìµœì  ëª¨ë¸ ì„ íƒ ê³ ë ¤")
    
    for rec in recommendations:
        report += f"{rec}\n"
    
    report += f"""

---

## ğŸ“ ì €ì¥ëœ íŒŒì¼

ëª¨ë¸ ë° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ì€ ë‹¤ìŒ ìœ„ì¹˜ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:

- `models/price_prediction_model.joblib`: í›ˆë ¨ëœ ëª¨ë¸
- `models/scaler.joblib`: íŠ¹ì§• ìŠ¤ì¼€ì¼ëŸ¬
- `models/label_encoders.joblib`: ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”
- `models/feature_importance.json`: íŠ¹ì§• ì¤‘ìš”ë„ (JSON)
- `models/metrics.json`: ì„±ëŠ¥ ì§€í‘œ (JSON)

---

**ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
    
    # Save report
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"Training report saved to: {output_path}")
    return output_path


def get_feature_description(feature_name):
    """Get human-readable description of feature"""
    descriptions = {
        'price_per_unit': 'ë‹¨ìœ„ë‹¹ ê°€ê²© (íƒ€ê²Ÿê³¼ ìœ ì‚¬í•˜ì—¬ ì œì™¸ë¨)',
        'detail_PAD_max': 'ë¬¼ë¦¬ ê³µê²©ë ¥ ìµœëŒ€ê°’',
        'detail_MAD_sum': 'ë§ˆë²• ê³µê²©ë ¥ í•©ê³„',
        'detail_scroll_STR_sum': 'STR ìŠ¤í¬ë¡¤ í•©ê³„',
        'detail_MAD_max': 'ë§ˆë²• ê³µê²©ë ¥ ìµœëŒ€ê°’',
        'detail_PAD_sum': 'ë¬¼ë¦¬ ê³µê²©ë ¥ í•©ê³„',
        'name': 'ì•„ì´í…œ ì´ë¦„',
        'payload_item_id': 'ì•„ì´í…œ ID (payloadì—ì„œ)',
        'item_id': 'ì•„ì´í…œ ID',
        'star_force': 'ìŠ¤íƒ€í¬ìŠ¤',
        'potential_grade': 'ì ì¬ëŠ¥ë ¥ ë“±ê¸‰',
        'additional_grade': 'ì¶”ê°€ì˜µì…˜ ë“±ê¸‰',
        'detail_scroll_count': 'ìŠ¤í¬ë¡¤ ì‚¬ìš© íšŸìˆ˜',
        'potential_options_count': 'ì ì¬ëŠ¥ë ¥ ì˜µì…˜ ê°œìˆ˜',
        'additional_options_count': 'ì¶”ê°€ì˜µì…˜ ê°œìˆ˜',
        'year': 'ë…„ë„',
        'month': 'ì›”',
        'day_of_week': 'ìš”ì¼',
        'hour': 'ì‹œê°„',
    }
    
    # Try to match partial names
    for key, desc in descriptions.items():
        if key in feature_name.lower():
            return desc
    
    # Default descriptions based on prefixes
    if feature_name.startswith('detail_base_'):
        stat = feature_name.replace('detail_base_', '')
        return f'ê¸°ë³¸ {stat} ìŠ¤íƒ¯'
    elif feature_name.startswith('detail_scroll_'):
        stat = feature_name.replace('detail_scroll_', '').replace('_sum', '').replace('_max', '')
        return f'{stat} ìŠ¤í¬ë¡¤ ì¦ê°€ëŸ‰'
    elif feature_name.startswith('detail_'):
        stat = feature_name.replace('detail_', '').replace('_sum', '').replace('_max', '')
        return f'{stat} ê´€ë ¨ ëŠ¥ë ¥ì¹˜'
    elif feature_name.startswith('potential_'):
        return 'ì ì¬ëŠ¥ë ¥ ê´€ë ¨ íŠ¹ì§•'
    elif feature_name.startswith('additional_'):
        return 'ì¶”ê°€ì˜µì…˜ ê´€ë ¨ íŠ¹ì§•'
    elif 'year' in feature_name or 'month' in feature_name or 'day' in feature_name or 'hour' in feature_name:
        return 'ì‹œê°„ ê´€ë ¨ íŠ¹ì§•'
    else:
        return 'ê¸°íƒ€ íŠ¹ì§•'


if __name__ == "__main__":
    generate_report()

