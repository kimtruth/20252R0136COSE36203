# 메이플스토리 아이템 시세 예측 프로젝트 Progress Report

**작성일**: 2025-11-03  
**프로젝트명**: MapleStory Item Price Prediction  
**데이터셋**: MySQL 데이터베이스 (1,204,706개 거래 기록)

---

## 1. 문제 정의

### 1.1 문제 배경

메이플스토리(MMORPG) 게임 내 아이템 가격은 시장 변동성이 크고 다양한 요인에 의해 영향을 받습니다. 아이템의 가격을 정확히 예측할 수 있다면:

- **게임 경제 분석**: 시장 동향 파악 및 인플레이션 모니터링
- **거래 의사결정 지원**: 구매/판매 시점 최적화
- **가격 추천 시스템**: 자동 입찰/매입 시스템 구축

### 1.2 핵심 도전 과제

1. **복잡한 데이터 구조**
   - 아이템 정보가 중첩된 JSON 형태로 저장됨 (`payload_json`, `detail_json`, `summary_json`)
   - `potential_options`, `additional_options` 등 리스트 형태의 특징
   - 평평한(flat) 2D 테이블로 변환 필요

2. **다양한 특징 유형**
   - 수치형: 스타포스, 능력치, 스탯 증가량
   - 범주형: 아이템 이름, 잠재능력 등급
   - 시간 특징: 거래 시점, 등록 날짜

3. **시세 변동성**
   - 가격 범위가 매우 넓음 (50 ~ 1,999,999,999,999 메소)
   - 시간에 따른 가격 변동 (인플레이션, 업데이트 영향, 이벤트)
   - 아이템별 가격 분포 차이

### 1.3 목표

MySQL 데이터베이스에서 데이터를 추출하여 머신러닝 모델을 훈련하고, 아이템의 `payload_json` 정보만으로 가격을 예측하는 E2E 파이프라인 구축.

---

## 2. 시도한 방법론 소개

### 2.1 데이터 추출 및 전처리 (ETL Pipeline)

#### 2.1.1 데이터 추출
- **소스**: MySQL 데이터베이스 (`auction_history` 테이블)
- **데이터 규모**: 1,204,706개 거래 기록
- **주요 컬럼**: `trade_sn`, `name`, `item_id`, `price`, `payload_json`, `created_at`, `potential_grade`, `additional_grade` 등

#### 2.1.2 데이터 변환 (JSON Flattening)

중첩된 JSON 구조를 평평한 특징 벡터로 변환:

**1. 기본 특징 추출**
- `payload_json`에서 직접 추출: `star_force`, `potential_grade`, `additional_grade`, `scroll_count`
- 원본 테이블 컬럼: `item_id`, `name`, `count`, `potential_grade`, `additional_grade`

**2. 스탯 특징 추출** (`detail_json` 파싱)
- 기본 스탯: `base_STR`, `base_DEX`, `base_INT`, `base_LUK`
- 스크롤 스탯: `scroll_STR_sum`, `scroll_STR_max`, `scroll_DEX_sum`, `scroll_DEX_max` 등
- 능력치: `MHP_sum`, `MAD_sum`, `PAD_sum`, `PDD_sum` (합계 및 최대값)
- 퍼센트 스탯: `percent_MHP_sum`, `percent_IMDR_sum`, `percent_Damage_sum` 등
- 요구사항: `scroll_count`, `cuttable`

**3. 옵션 특징 추출**
- 잠재능력 (`potential_options`): `potential_options_count`, `potential_has_skill_cooldown`, `potential_has_stat_percent`, `potential_has_damage`
- 추가옵션 (`additional_options`): `additional_options_count`, `additional_has_skill_cooldown` 등

**4. 시간 특징 추출**
- `created_at`, `trade_date`, `register_date`에서 추출
- `year`, `month`, `day`, `day_of_week`, `hour`, `day_of_year` 등

**5. 범주형 변수 인코딩**
- `LabelEncoder`를 사용하여 `item_id`, `name` 등 범주형 변수 인코딩

**6. 특징 스케일링**
- `StandardScaler`를 사용하여 수치형 특징 정규화

#### 2.1.3 데이터 적재
- 전처리된 데이터를 Parquet 형식으로 저장 (`data/processed/preprocessed_data.parquet`)
- 파일 크기: ~963MB
- 재사용을 위한 캐싱 메커니즘 구현

### 2.2 모델 훈련

#### 2.2.1 데이터 분할
- **Train**: 70% (랜덤 샘플링)
- **Validation**: 10% (랜덤 샘플링)
- **Test**: 20% (랜덤 샘플링)

**참고**: 시간 순서 기반 분할을 고려했으나, 시간 패턴을 모든 시점에서 학습하기 위해 랜덤 샘플링 채택. 시간 특징(year, month, day_of_week 등)은 특징으로 포함되어 시간 패턴 학습 가능.

#### 2.2.2 시도한 모델

**1. Random Forest Regressor**
- **하이퍼파라미터**: `n_estimators=100`, `max_depth=None`, `random_state=42`
- **특징**: 앙상블 기반, 특징 중요도 제공, 비교 기준 모델

**2. LightGBM Regressor**
- **하이퍼파라미터**: 
  - `n_estimators=100`, `max_depth=-1`, `learning_rate=0.1`
  - `num_leaves=31`, `feature_fraction=0.9`, `bagging_fraction=0.8`
  - `min_child_samples=20`
- **특징**: 
  - Gradient Boosting 기반
  - Early stopping (validation set 사용)
  - 빠른 훈련 속도 및 메모리 효율성

### 2.3 모델 평가

**평가 지표**:
- **RMSE** (Root Mean Squared Error): 예측 오차의 제곱근
- **MAE** (Mean Absolute Error): 평균 절대 오차
- **R² Score**: 설명력 (0~1, 높을수록 좋음)
- **MAPE** (Mean Absolute Percentage Error): 평균 절대 백분율 오차

**과적합 분석**:
- Train R²와 Test R²의 차이로 측정
- 차이가 클수록 과적합이 심함

### 2.4 모델 저장 및 배포

- 훈련된 모델: `joblib` 형식으로 저장
- 전처리 파이프라인: `scaler.joblib`, `label_encoders.joblib` 저장
- 특징 중요도: JSON 형식으로 저장
- 성능 지표: JSON 형식으로 저장

### 2.5 예측 시스템

`payload_json`을 입력받아 가격을 예측하는 스크립트 구현:
- JSON 파일, JSON 문자열, 인터랙티브 모드 지원
- 실제 가격과 비교하여 오차 계산
- 특징 중요도 Top 5 표시

---

## 3. 중간 결과 및 해석

### 3.1 데이터 전처리 결과

- **전처리 전**: 14개 컬럼 (원본 테이블)
- **전처리 후**: 69개 특징 (JSON flattening 후)
- **최종 특징 수**: 61개 (타겟 및 제외 컬럼 제거 후)

### 3.2 모델 성능 비교

| 모델 | Train R² | Val R² | Test R² | Test RMSE | Test MAE | 과적합 |
|------|----------|--------|---------|-----------|----------|--------|
| **Random Forest** | 0.9699 | 0.8299 | 0.6270 | 6,388억 | 5.33억 | 심함 (0.3429) |
| **LightGBM** | 0.7941 | 0.8310 | **0.8009** | **3,928억** | 6.55억 | 없음 (-0.0068) |

### 3.3 주요 발견사항

#### 3.3.1 LightGBM의 우수한 성능

1. **R² Score 개선**: 0.6270 → 0.8009 (+27.75% 개선)
   - 가격 변동의 약 80%를 설명
   - Random Forest 대비 상당한 개선

2. **과적합 문제 해결**
   - Random Forest: Train R² 0.9699 vs Test R² 0.6270 (차이 0.3429) → 심한 과적합
   - LightGBM: Train R² 0.7941 vs Test R² 0.8009 (차이 -0.0068) → 과적합 없음
   - Validation R²가 Test R²보다 높은 것은 일반화가 잘 되고 있음을 의미

3. **RMSE 개선**: 6,388억 → 3,928억 (38.5% 감소)
   - 큰 오차가 크게 줄어듦

4. **모델 효율성**
   - Random Forest: 6.2GB
   - LightGBM: 247KB (약 25,000배 작음)
   - 훨씬 빠른 예측 속도

#### 3.3.2 특징 중요도 분석

**Random Forest Top 5 특징**:
1. `detail_PAD_max` (물리 공격력 최대값) - 28.43%
2. `detail_MAD_max` (마법 공격력 최대값) - 10.10%
3. `additional_grade` (추가옵션 등급) - 7.89%
4. `payload_potential_grade` (잠재능력 등급) - 5.46%
5. `potential_grade` (잠재능력 등급) - 5.44%

**분석**:
- 아이템의 능력치(공격력)가 가격에 가장 큰 영향
- 잠재능력 및 추가옵션 등급이 중요한 역할
- 아이템 ID와 이름도 일정 영향 (아이템별 가격 차이)

#### 3.3.3 예측 정확도 예시

테스트 샘플:
- 실제 가격: 280억 메소
- 예측 가격: 246.24억 메소
- 오차: 12.06%

### 3.4 성능 개선 요약

| 항목 | Random Forest | LightGBM | 개선율 |
|------|---------------|----------|--------|
| R² Score | 0.6270 | **0.8009** | **+27.75%** |
| RMSE | 6,388억 | **3,928억** | **-38.5%** |
| 과적합 | 심함 | 없음 | **완전 해결** |
| 모델 크기 | 6.2GB | 247KB | **99.996% 감소** |

---

## 4. 개선이 필요한 부분과 개선 계획

### 4.1 현재 문제점

#### 4.1.1 MAE 증가
- **문제**: LightGBM의 MAE가 Random Forest보다 높음 (5.33억 → 6.55억)
- **원인**: RMSE 최적화에 집중하여 평균 절대 오차가 증가
- **영향**: 전체적으로는 큰 오차가 줄었지만, 평균적인 예측 오차는 증가

#### 4.1.2 MAPE 지표의 신뢰성
- **문제**: MAPE가 매우 높음 (36,670%)
- **원인**: 가격 범위가 매우 넓어서 (50 ~ 1,999,999,999,999) 작은 가격의 오차가 비율적으로 매우 큼
- **해결 필요**: MAPE 대신 다른 지표 사용 고려

#### 4.1.3 하이퍼파라미터 미튜닝
- **현재**: 기본값 사용
- **개선 필요**: 최적 하이퍼파라미터 탐색

#### 4.1.4 특징 엔지니어링 부족
- **현재**: JSON에서 기본적인 특징만 추출
- **개선 가능**: 
  - 아이템 카테고리별 가격 분포 특징
  - 능력치 조합 특징
  - 시간적 트렌드 특징 (이전 N일 평균 가격 등)

#### 4.1.5 가격 범위에 따른 모델 분리 미고려
- **문제**: 가격 범위가 매우 넓어서 하나의 모델로 모든 가격대를 예측하기 어려움
- **개선 필요**: 가격대별 모델 분리 또는 앙상블

### 4.2 개선 계획

#### 4.2.1 단기 개선 (1-2주)

**1. 하이퍼파라미터 튜닝**
```python
# LightGBM 하이퍼파라미터 그리드 서치
- num_leaves: [31, 50, 100]
- learning_rate: [0.05, 0.1, 0.2]
- feature_fraction: [0.8, 0.9, 1.0]
- bagging_fraction: [0.7, 0.8, 0.9]
- min_child_samples: [10, 20, 30]
```
- **예상 효과**: R² Score 0.82~0.85 수준 개선 가능

**2. MAE 최적화**
- Loss function을 MAE로 변경하여 평균 절대 오차 최소화
- 또는 Quantile Loss 사용 (중앙값 예측)

**3. 평가 지표 개선**
- MAPE 대신 Symmetric MAPE (SMAPE) 사용
- 또는 로그 스케일 RMSE 사용
- 가격대별 오차 분석

**4. 특징 엔지니어링 강화**
- 아이템 카테고리 인코딩 (`category` 필드 활용)
- 능력치 조합 특징 생성 (예: `total_attack = PAD + MAD`)
- 스탯 효율성 특징 (능력치 대비 가격 비율)

#### 4.2.2 중기 개선 (1개월)

**1. 앙상블 모델**
- Random Forest + LightGBM 앙상블
- Weighted Average 또는 Stacking 사용
- **예상 효과**: R² Score 0.85+ 가능

**2. 가격대별 모델 분리**
- 저가 (0~1억), 중가 (1억~100억), 고가 (100억+) 모델 분리
- 각 가격대별 최적화된 모델 사용
- **예상 효과**: 각 가격대별 정확도 향상

**3. 시간적 특징 강화**
- 이동 평균 가격 (최근 N일 평균)
- 가격 변동률 (전일 대비)
- 계절성 특징 (요일, 시간대별 패턴)

**4. 이상치 처리**
- 가격 이상치 탐지 및 제거/변환
- IQR 방법 또는 Z-score 사용

#### 4.2.3 장기 개선 (2-3개월)

**1. 딥러닝 모델 시도**
- TabNet, TabTransformer 등 테이블 데이터용 딥러닝 모델
- 텍스트 특징 (아이템 이름, 옵션 설명) 임베딩
- **예상 효과**: 복잡한 비선형 관계 학습 가능

**2. 시계열 모델 결합**
- 아이템별 시계열 가격 데이터 모델링
- LSTM/GRU를 사용한 가격 트렌드 예측
- **예상 효과**: 시간적 패턴 학습 강화

**3. 추가 데이터 활용**
- 아이템 등급 정보
- 서버별 가격 차이
- 거래량 정보

**4. 실시간 예측 시스템 구축**
- API 서버 구축
- 배치 예측 스케줄링
- 모델 자동 재훈련 파이프라인

### 4.3 우선순위별 개선 로드맵

| 우선순위 | 개선 항목 | 예상 효과 | 난이도 | 소요 시간 |
|---------|----------|----------|--------|----------|
| **높음** | 하이퍼파라미터 튜닝 | R² +0.02~0.05 | 낮음 | 1일 |
| **높음** | MAE 최적화 | MAE -20~30% | 중간 | 2일 |
| **중간** | 특징 엔지니어링 강화 | R² +0.01~0.03 | 중간 | 3일 |
| **중간** | 앙상블 모델 | R² +0.02~0.04 | 중간 | 2일 |
| **낮음** | 가격대별 모델 분리 | 각 가격대별 정확도 향상 | 높음 | 1주 |
| **낮음** | 딥러닝 모델 시도 | R² +0.03~0.05 | 높음 | 2주 |

### 4.4 예상 최종 성능

현재 LightGBM 성능을 기준으로 개선 계획을 실행하면:

| 지표 | 현재 | 예상 최종 |
|------|------|----------|
| **R² Score** | 0.8009 | **0.85~0.88** |
| **RMSE** | 3,928억 | **3,000~3,500억** |
| **MAE** | 6.55억 | **4.5~5.5억** |
| **과적합** | 없음 | 없음 유지 |

---

## 5. 결론

### 5.1 달성한 성과

1. ✅ **E2E 파이프라인 구축 완료**
   - 데이터 추출 → 전처리 → 훈련 → 평가 → 저장 → 예측

2. ✅ **복잡한 JSON 데이터 처리**
   - 중첩된 JSON 구조를 69개 특징으로 변환

3. ✅ **과적합 문제 해결**
   - Random Forest의 심한 과적합을 LightGBM으로 해결

4. ✅ **성능 개선**
   - R² Score 27.75% 개선 (0.6270 → 0.8009)
   - RMSE 38.5% 개선

5. ✅ **실용적인 예측 시스템**
   - `payload_json`만으로 가격 예측 가능
   - 다양한 입력 방식 지원

### 5.2 학습한 내용

1. **시계열 데이터의 랜덤 샘플링**: 시간 특징을 유지하면서 시간 패턴을 학습하는 방법
2. **과적합 해결**: Early stopping과 정규화를 통한 일반화 성능 향상
3. **모델 비교**: 다양한 모델의 성능 비교 및 최적 모델 선택
4. **특징 엔지니어링**: 복잡한 JSON 구조에서 의미있는 특징 추출

### 5.3 향후 방향

프로젝트는 좋은 출발을 했습니다. LightGBM 모델로 80%의 설명력을 달성했고, 과적합 없이 안정적인 성능을 보이고 있습니다. 하이퍼파라미터 튜닝과 특징 엔지니어링을 통해 85% 이상의 R² Score 달성이 가능할 것으로 예상됩니다.

---

**보고서 작성 완료**: 2025-11-03

