{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MapleStory Item Price Prediction - Google Colab\n",
        "\n",
        "This notebook runs the complete pipeline for training a price prediction model.\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "1. **Upload your project files**: Upload the entire `src/` directory and `requirements.txt` to Colab\n",
        "2. **Upload your data**: Upload raw data (`.jsonl`) or preprocessed data (`.parquet`) files\n",
        "3. **Run all cells**: Execute cells in order\n",
        "\n",
        "## Data Options\n",
        "- **Option 1**: Upload raw `.jsonl` files (will be preprocessed)\n",
        "- **Option 2**: Upload preprocessed `.parquet` files (faster, skips preprocessing)\n",
        "- **Option 3**: Connect to database (requires credentials)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install -q joblib>=1.5.2 numpy>=2.3.4 pandas>=2.3.3 pymysql>=1.1.2 python-dotenv>=1.2.1 scikit-learn>=1.7.2 pyarrow>=18.0.0 lightgbm>=4.0.0\n",
        "\n",
        "print(\"✓ Dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Setup Project Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs('data/processed', exist_ok=True)\n",
        "os.makedirs('data/raw', exist_ok=True)\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Add current directory to path\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "print(\"✓ Project structure created!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Upload Data Files\n",
        "\n",
        "Choose one of the following options:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option A: Upload Raw Data Files (.jsonl)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Upload raw data files\n",
        "print(\"Please upload your .jsonl data files:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files to data/raw directory\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.jsonl'):\n",
        "        shutil.move(filename, f'data/raw/{filename}')\n",
        "        print(f\"✓ Moved {filename} to data/raw/\")\n",
        "    else:\n",
        "        print(f\"⚠ Skipping {filename} (not a .jsonl file)\")\n",
        "\n",
        "print(\"\\n✓ File upload complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option B: Upload Preprocessed Data (.parquet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "# Upload preprocessed data files\n",
        "print(\"Please upload your .parquet data files:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move uploaded files to data/processed directory\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.parquet'):\n",
        "        shutil.move(filename, f'data/processed/{filename}')\n",
        "        print(f\"✓ Moved {filename} to data/processed/\")\n",
        "    else:\n",
        "        print(f\"⚠ Skipping {filename} (not a .parquet file)\")\n",
        "\n",
        "print(\"\\n✓ File upload complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option C: Mount Google Drive (Alternative)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Example: Copy files from Drive\n",
        "# !cp /content/drive/MyDrive/path/to/your/data.jsonl /content/data/raw/\n",
        "\n",
        "print(\"✓ Google Drive mounted!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Upload Project Source Files\n",
        "\n",
        "Upload the `src/` directory. You can zip it first and upload, then unzip:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "\n",
        "# Upload zip file containing src/ directory\n",
        "print(\"Please upload a zip file containing the src/ directory:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Extract zip file\n",
        "for filename in uploaded.keys():\n",
        "    if filename.endswith('.zip'):\n",
        "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        print(f\"✓ Extracted {filename}\")\n",
        "        os.remove(filename)  # Clean up zip file\n",
        "    else:\n",
        "        print(f\"⚠ Skipping {filename} (not a zip file)\")\n",
        "\n",
        "print(\"\\n✓ Project files extracted!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Configure Data Source\n",
        "\n",
        "Set the path to your data file. Modify the variables below based on your upload:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "USE_PREPROCESSED = False  # Set to True if you uploaded preprocessed .parquet files\n",
        "JSONL_FILE_PATH = 'data/raw/raw_data.jsonl'  # Path to your raw JSONL file\n",
        "PREPROCESSED_FILE_PATH = 'data/processed/preprocessed_data.parquet'  # Path to preprocessed file\n",
        "DATA_LIMIT = None  # Set to a number (e.g., 10000) to limit rows, or None for all data\n",
        "\n",
        "# Check what files are available\n",
        "import os\n",
        "\n",
        "print(\"Available files:\")\n",
        "if os.path.exists('data/raw'):\n",
        "    raw_files = [f for f in os.listdir('data/raw') if f.endswith('.jsonl')]\n",
        "    print(f\"  Raw files: {raw_files}\")\n",
        "    if raw_files:\n",
        "        JSONL_FILE_PATH = f\"data/raw/{raw_files[0]}\"\n",
        "        print(f\"  → Using: {JSONL_FILE_PATH}\")\n",
        "\n",
        "if os.path.exists('data/processed'):\n",
        "    processed_files = [f for f in os.listdir('data/processed') if f.endswith('.parquet')]\n",
        "    print(f\"  Preprocessed files: {processed_files}\")\n",
        "    if processed_files:\n",
        "        PREPROCESSED_FILE_PATH = f\"data/processed/{processed_files[0]}\"\n",
        "        print(f\"  → Using: {PREPROCESSED_FILE_PATH}\")\n",
        "        USE_PREPROCESSED = True\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Use preprocessed: {USE_PREPROCESSED}\")\n",
        "print(f\"  Data limit: {DATA_LIMIT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Run Pipeline\n",
        "\n",
        "Choose your model type and run the training pipeline:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import pipeline\n",
        "from src.pipeline import run_pipeline\n",
        "import pandas as pd\n",
        "\n",
        "# Model configuration\n",
        "MODEL_TYPE = 'lightgbm'  # Options: 'random_forest', 'gradient_boosting', 'lightgbm'\n",
        "TEST_SIZE = 0.2\n",
        "VAL_SIZE = 0.1\n",
        "\n",
        "# Run pipeline\n",
        "if USE_PREPROCESSED:\n",
        "    # Use preprocessed data\n",
        "    print(f\"Using preprocessed data from: {PREPROCESSED_FILE_PATH}\")\n",
        "    results = run_pipeline(\n",
        "        data_limit=DATA_LIMIT,\n",
        "        model_type=MODEL_TYPE,\n",
        "        test_size=TEST_SIZE,\n",
        "        val_size=VAL_SIZE,\n",
        "        preprocessed_data_path=PREPROCESSED_FILE_PATH,\n",
        "        save_processed=True\n",
        "    )\n",
        "else:\n",
        "    # Load from JSONL file\n",
        "    print(f\"Loading from JSONL file: {JSONL_FILE_PATH}\")\n",
        "    results = run_pipeline(\n",
        "        data_limit=DATA_LIMIT,\n",
        "        model_type=MODEL_TYPE,\n",
        "        test_size=TEST_SIZE,\n",
        "        val_size=VAL_SIZE,\n",
        "        jsonl_path=JSONL_FILE_PATH,\n",
        "        save_processed=True\n",
        "    )\n",
        "\n",
        "print(\"\\n✓ Pipeline completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Download Results\n",
        "\n",
        "Download your trained models and results:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Create a zip file with models and results\n",
        "output_zip = 'maple_meso_results.zip'\n",
        "\n",
        "with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "    # Add models directory\n",
        "    if os.path.exists('models'):\n",
        "        for root, dirs, files_list in os.walk('models'):\n",
        "            for file in files_list:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zipf.write(file_path, os.path.relpath(file_path, '.'))\n",
        "    \n",
        "    # Add reports\n",
        "    for report_file in ['TRAINING_REPORT.md', 'TRAINING_REPORT_lightgbm.md', 'MODEL_COMPARISON.md']:\n",
        "        if os.path.exists(report_file):\n",
        "            zipf.write(report_file)\n",
        "\n",
        "print(f\"✓ Created {output_zip}\")\n",
        "files.download(output_zip)\n",
        "print(\"\\n✓ Download started!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Make Predictions\n",
        "\n",
        "Use the trained model to make predictions on new data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.predict import predict_price\n",
        "\n",
        "# Example prediction\n",
        "example_item = {\n",
        "    \"name\": \"앱솔랩스 메이지크라운\",\n",
        "    \"item_id\": 1004423,\n",
        "    \"star_force\": 22,\n",
        "    \"potential_grade\": 4,\n",
        "    \"additional_grade\": 4,\n",
        "    \"payload_json\": {\n",
        "        \"detail_json\": \"{}\",  # Add your detail_json here\n",
        "        \"summary_json\": \"{}\",  # Add your summary_json here\n",
        "    }\n",
        "}\n",
        "\n",
        "# Make prediction\n",
        "result = predict_price(example_item)\n",
        "print(f\"Predicted price: {result['predicted_price_formatted']} 메소\")\n",
        "print(f\"Confidence: {result.get('confidence', 'N/A')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Troubleshooting\n",
        "\n",
        "### Import Errors\n",
        "- Make sure you uploaded the `src/` directory\n",
        "- Check that all files are in the correct location\n",
        "\n",
        "### File Not Found\n",
        "- Verify file paths match your uploaded files\n",
        "- Check the file names in `data/raw/` or `data/processed/` directories\n",
        "\n",
        "### Memory Issues\n",
        "- Reduce `DATA_LIMIT` to process smaller batches\n",
        "- Use preprocessed data instead of raw data\n",
        "- Consider using Colab Pro for more RAM\n",
        "\n",
        "### Database Connection (if needed)\n",
        "If you need to connect to a database, set environment variables:\n",
        "```python\n",
        "import os\n",
        "os.environ['MAPLE_DB_HOST'] = 'your-host'\n",
        "os.environ['MAPLE_DB_USER'] = 'your-user'\n",
        "os.environ['MAPLE_DB_PASSWORD'] = 'your-password'\n",
        "os.environ['MAPLE_DB_NAME'] = 'your-database'\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
