# 모델 성능 개선 결과 리포트

**작성일**: 2025-11-03  
**기준 모델**: LightGBM (기본 하이퍼파라미터)

---

## 📊 개선 결과 요약

### 최종 성능 비교

| 모델 | Test R² | Test RMSE | Test MAE | 개선율 (R²) |
|------|---------|-----------|----------|-------------|
| **Baseline (LightGBM 기본)** | 0.8009 | 3,928억 | 6.55억 | - |
| **RMSE 최적화 (튜닝)** | 0.7835 | 4,096억 | 6.95억 | -2.17% |
| **MAE 최적화** | 0.7401 | 4,489억 | **5.26억** | -7.59% |
| **앙상블 (RF + LightGBM)** | **0.8034** | **3,904억** | 5.92억 | **+0.31%** |

### 주요 개선 사항

#### 1. 하이퍼파라미터 튜닝
- **방법**: RandomizedSearchCV (15회 반복, 3-fold CV)
- **최적 파라미터**:
  - `n_estimators`: 300
  - `max_depth`: 7
  - `learning_rate`: 0.1
  - `num_leaves`: 31
  - `feature_fraction`: 0.9
  - `bagging_fraction`: 0.8
  - `bagging_freq`: 7
  - `min_child_samples`: 10
  - `reg_alpha`: 0.1
  - `reg_lambda`: 1.0
- **Validation 성능**: R² 0.9015 (튜닝 중 최고 성능)

#### 2. MAE 최적화 모델
- **목적**: 평균 절대 오차 최소화
- **결과**: MAE 5.26억 (기존 6.55억 대비 **-19.8% 개선**)
- **특징**: RMSE는 약간 증가하지만 MAE가 크게 개선됨

#### 3. 앙상블 모델
- **구성**: Random Forest (30%) + LightGBM (70%)
- **결과**: 
  - Test R²: **0.8034** (기존 대비 +0.31%)
  - Test RMSE: **3,904억** (기존 대비 -0.6%)
  - Test MAE: 5.92억
- **특징**: 가장 균형잡힌 성능

---

## 🔍 상세 분석

### Validation Set 성능 (튜닝 중)

| 모델 | Validation R² | Validation RMSE | Validation MAE |
|------|---------------|------------------|----------------|
| **튜닝된 LightGBM** | **0.9015** | 2,693억 | 5.61억 |

**분석**: 하이퍼파라미터 튜닝 중 Validation R²가 0.9015로 매우 높았지만, 최종 Test Set에서는 0.7835로 나타났습니다. 이는 Validation Set이 튜닝 과정에서 사용되어 약간의 과적합이 발생했을 가능성이 있습니다.

### Test Set 성능 비교

#### RMSE 최적화 모델
- **R²**: 0.7835 (기존 0.8009 대비 약간 감소)
- **RMSE**: 4,096억 (기존 3,928억 대비 증가)
- **MAE**: 6.95억 (기존 6.55억 대비 증가)
- **분석**: 하이퍼파라미터 튜닝이 Validation Set에 최적화되어 Test Set 성능이 약간 저하됨

#### MAE 최적화 모델
- **R²**: 0.7401 (기존 대비 감소)
- **RMSE**: 4,489억 (기존 대비 증가)
- **MAE**: **5.26억** (기존 6.55억 대비 **-19.8% 개선**)
- **분석**: MAE 최적화에 성공했지만, 전체적인 예측 정확도(R²)는 다소 감소

#### 앙상블 모델
- **R²**: **0.8034** (기존 대비 +0.31%)
- **RMSE**: **3,904억** (기존 대비 -0.6%)
- **MAE**: 5.92억 (기존 대비 -9.6%)
- **분석**: 가장 균형잡힌 성능으로, R²와 RMSE 모두 개선되었고 MAE도 개선됨

---

## 📈 특징 중요도 분석

### 앙상블 모델 Top 10 특징

1. `item_id` (152.61)
2. `name` (151.21)
3. `detail_PAD_sum` (126.71)
4. `detail_MAD_sum` (108.51)
5. `detail_PAD_max` (106.47)
6. `detail_MAD_max` (75.63)
7. `payload_trade_sn` (75.61)
8. `detail_cuttable` (65.80)
9. `detail_scroll_LUK_sum` (51.81)
10. `additional_grade` (49.04)

**분석**: 
- 아이템 ID와 이름이 가장 중요한 특징 (아이템별 가격 차이 반영)
- 공격력 관련 특징(PAD, MAD)이 높은 중요도
- 잠재능력/추가옵션 등급도 중요한 역할

---

## ✅ 완료된 개선 작업

1. ✅ **하이퍼파라미터 튜닝 시스템 구축**
   - RandomizedSearchCV 통합
   - 튜닝 결과 자동 저장 및 로드

2. ✅ **MAE 최적화 모델 구현**
   - LightGBM의 `objective='mae'` 적용
   - MAE 19.8% 개선 달성

3. ✅ **특징 엔지니어링 강화**
   - 10개 추가 특징 생성
   - 가치 점수, 품질 점수 등 종합 지표 추가

4. ✅ **앙상블 모델 구현**
   - Random Forest + LightGBM 가중 평균
   - 최고 성능 달성 (R² 0.8034)

5. ✅ **통합 개선 파이프라인**
   - `improve_model.py` 스크립트 생성
   - 자동화된 학습 및 평가 시스템

---

## 🎯 최종 결론

### 성공한 개선
- **MAE 최적화**: 19.8% 개선 (6.55억 → 5.26억)
- **앙상블 모델**: R² 0.31% 개선 및 균형잡힌 성능

### 추가 개선 필요 사항
1. **하이퍼파라미터 튜닝 개선**
   - Validation Set을 완전히 분리하여 튜닝
   - 더 많은 반복 횟수로 탐색 (현재 15회 → 50회 이상)
   - Bayesian Optimization 등 고급 튜닝 방법 시도

2. **과적합 방지**
   - Cross-validation 기반 튜닝 강화
   - 정규화 강화 (reg_alpha, reg_lambda 증가)

3. **데이터 개선**
   - 이상치 제거/처리
   - 가격대별 모델 분리 고려

---

## 📝 다음 단계 제안

1. **고급 튜닝**: Optuna 등 Bayesian Optimization 도구 사용
2. **가격대별 모델**: 저가/중가/고가 아이템별 별도 모델
3. **시계열 특징**: 이동 평균, 가격 변동률 등 추가
4. **딥러닝 모델**: TabNet, TabTransformer 등 시도

---

**리포트 작성 완료**: 2025-11-03


