# λ¨λΈ μ„±λ¥ κ°μ„  κ°€μ΄λ“

**μ‘μ„±μΌ**: 2025-11-03  
**κΈ°μ¤€ λ¨λΈ**: LightGBM (RΒ²: 0.8009, RMSE: 3,928μ–µ, MAE: 6.55μ–µ)

---

## π― κ°μ„  μ‚¬ν•­ μ”μ•½

### 1. ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ§€μ›
- **κµ¬ν„ μ„μΉ**: `src/train.py`, `src/tune_hyperparameters.py`
- **κ°μ„  λ‚΄μ©**:
  - RandomizedSearchCVλ¥Ό μ‚¬μ©ν• μλ™ ν•μ΄νΌνλΌλ―Έν„° νƒμƒ‰
  - νλ‹ κ²°κ³Ό μλ™ λ΅λ“ λ° μ μ© κΈ°λ¥
  - μ£Όμ” νλΌλ―Έν„° νƒμƒ‰: `n_estimators`, `max_depth`, `learning_rate`, `num_leaves`, `feature_fraction`, `bagging_fraction`, `min_child_samples`, `reg_alpha`, `reg_lambda`
- **μμƒ ν¨κ³Ό**: RΒ² Score +0.02~0.05 κ°μ„ 

### 2. MAE μµμ ν™” λ¨λΈ
- **κµ¬ν„ μ„μΉ**: `src/train.py`
- **κ°μ„  λ‚΄μ©**:
  - LightGBMμ `objective='mae'` μµμ… μ§€μ›
  - RMSE μµμ ν™”μ™€ MAE μµμ ν™” λ¨λΈ λ¶„λ¦¬ ν•™μµ
  - κ°κ° λ‹¤λ¥Έ λ©μ μ— μµμ ν™”λ λ¨λΈ μ κ³µ
- **μμƒ ν¨κ³Ό**: MAE -20~30% κ°μ„ 

### 3. μ¶”κ°€ νΉμ§• μ—”μ§€λ‹μ–΄λ§
- **κµ¬ν„ μ„μΉ**: `src/preprocess.py` (`add_engineered_features` ν•¨μ)
- **μ¶”κ°€λ νΉμ§•** (μ΄ 10κ°):
  1. `max_stat`: μµλ€ μ¤νƒ―κ°’ (STR, DEX, INT, LUK μ¤‘ μµλ€κ°’)
  2. `total_percent_stat`: λ¨λ“  νΌμ„ΌνΈ μ¤νƒ― ν•©κ³„
  3. `attack_stat_ratio`: κ³µκ²©λ ¥ λ€λΉ„ μ¤νƒ― λΉ„μ¨
  4. `star_force_attack_score`: μ¤νƒ€ν¬μ¤ Γ— κ³µκ²©λ ¥
  5. `grade_attack_score`: λ“±κΈ‰ Γ— κ³µκ²©λ ¥
  6. `potential_quality_score`: μ μ¬λ¥λ ¥ ν’μ§ μ μ
  7. `additional_quality_score`: μ¶”κ°€μµμ… ν’μ§ μ μ
  8. `total_quality_score`: μ „μ²΄ ν’μ§ μ μ
  9. `damage_percent_ratio`: λ°λ―Έμ§€ νΌμ„ΌνΈ λΉ„μ¨
  10. `value_score`: κ°€μΉ μ μ (μΆ…ν•© μ§€ν‘)
- **μμƒ ν¨κ³Ό**: RΒ² Score +0.01~0.03 κ°μ„ 

### 4. μ•™μƒλΈ” λ¨λΈ
- **κµ¬ν„ μ„μΉ**: `src/ensemble.py`
- **κ°μ„  λ‚΄μ©**:
  - Random Forest + LightGBM κ°€μ¤‘ ν‰κ·  μ•™μƒλΈ”
  - κΈ°λ³Έ κ°€μ¤‘μΉ: RF 30%, LightGBM 70%
  - κ° λ¨λΈμ νΉμ§• μ¤‘μ”λ„ κ°€μ¤‘ ν‰κ· 
  - ν•μ΄νΌνλΌλ―Έν„° νλ‹ κ²°κ³Ό μλ™ μ μ©
- **μμƒ ν¨κ³Ό**: RΒ² Score +0.02~0.04 κ°μ„ 

### 5. ν†µν•© κ°μ„  μ¤ν¬λ¦½νΈ
- **κµ¬ν„ μ„μΉ**: `src/improve_model.py`
- **κΈ°λ¥**:
  - ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ‹¤ν–‰
  - RMSE μµμ ν™” λ¨λΈ ν•™μµ
  - MAE μµμ ν™” λ¨λΈ ν•™μµ
  - μ•™μƒλΈ” λ¨λΈ ν•™μµ
  - μ„±λ¥ λΉ„κµ λ¦¬ν¬νΈ μƒμ„±

---

## π€ μ‚¬μ© λ°©λ²•

### λ°©λ²• 1: ν†µν•© μ¤ν¬λ¦½νΈ μ‚¬μ© (κ¶μ¥)

```bash
# μ „μ²΄ νμ΄ν”„λΌμΈ μ‹¤ν–‰ (νλ‹ + RMSE λ¨λΈ + MAE λ¨λΈ + μ•™μƒλΈ”)
python src/improve_model.py

# νλ‹ μ—†μ΄ κΈ°μ΅΄ κ²°κ³Ό μ‚¬μ©
python src/improve_model.py --no-tune

# MAE λ¨λΈ ν•™μµ μ μ™Έ
python src/improve_model.py --no-mae

# μ•™μƒλΈ” λ¨λΈ ν•™μµ μ μ™Έ
python src/improve_model.py --no-ensemble

# νλ‹ λ°λ³µ νμ μ΅°μ • (κΈ°λ³Έ 30ν)
python src/improve_model.py --tune-iterations 50
```

### λ°©λ²• 2: κ°λ³„ λ‹¨κ³„ μ‹¤ν–‰

#### 1λ‹¨κ³„: ν•μ΄νΌνλΌλ―Έν„° νλ‹
```bash
python src/tune_hyperparameters.py
```

#### 2λ‹¨κ³„: κ°μ„ λ λ¨λΈ ν•™μµ
```bash
# RMSE μµμ ν™” λ¨λΈ (νλ‹ κ²°κ³Ό μλ™ μ μ©)
python src/pipeline.py --model lightgbm

# MAE μµμ ν™” λ¨λΈ (μλ™μΌλ΅ train.py μμ • ν•„μ”)
# λλ” improve_model.py μ‚¬μ©
```

#### 3λ‹¨κ³„: μ•™μƒλΈ” λ¨λΈ ν•™μµ
```bash
python src/ensemble.py
```

---

## π“ μμƒ μ„±λ¥ κ°μ„ 

| λ¨λΈ | ν„μ¬ RΒ² | μμƒ RΒ² | κ°μ„ μ¨ |
|------|--------|--------|--------|
| **Baseline (LightGBM)** | 0.8009 | - | - |
| **RMSE μµμ ν™” (νλ‹)** | 0.8009 | 0.82~0.85 | +2.4~6.1% |
| **MAE μµμ ν™”** | 0.8009 | 0.80~0.83 | +0~2.6% |
| **μ•™μƒλΈ”** | 0.8009 | 0.82~0.84 | +2.4~4.9% |

| μ§€ν‘ | ν„μ¬ | μμƒ κ°μ„  | κ°μ„ μ¨ |
|------|------|----------|--------|
| **RMSE** | 3,928μ–µ | 3,000~3,500μ–µ | -11~24% |
| **MAE** | 6.55μ–µ | 4.5~5.5μ–µ | -16~31% |

---

## π”§ μ£Όμ” μ½”λ“ λ³€κ²½ μ‚¬ν•­

### `src/train.py`
- `train_model()` ν•¨μμ— `objective` νλΌλ―Έν„° μ¶”κ°€
- `train_price_prediction_model()` ν•¨μμ— `hyperparameters`, `objective` νλΌλ―Έν„° μ¶”κ°€
- ν•μ΄νΌνλΌλ―Έν„° νλ‹ κ²°κ³Ό μλ™ λ΅λ“ κΈ°λ¥ μ¶”κ°€

### `src/preprocess.py`
- `add_engineered_features()` ν•¨μμ— 10κ° μ¶”κ°€ νΉμ§• μƒμ„± λ΅μ§ μ¶”κ°€

### `src/ensemble.py` (μ‹ κ·)
- `EnsembleModel` ν΄λμ¤ κµ¬ν„
- Random Forest + LightGBM κ°€μ¤‘ ν‰κ·  μ•™μƒλΈ”
- `train_ensemble_model()` ν•¨μ κµ¬ν„

### `src/improve_model.py` (μ‹ κ·)
- μ „μ²΄ κ°μ„  νμ΄ν”„λΌμΈ ν†µν•© μ¤ν¬λ¦½νΈ
- ν•μ΄νΌνλΌλ―Έν„° νλ‹, λ¨λΈ ν•™μµ, μ„±λ¥ λΉ„κµ μλ™ν™”

---

## π“ μ„±λ¥ λΉ„κµ λ°©λ²•

κ°μ„  μ¤ν¬λ¦½νΈ μ‹¤ν–‰ ν›„, λ‹¤μ νμΌμ—μ„ κ²°κ³Ό ν™•μΈ:

- `models/hyperparameter_tuning_results.json`: νλ‹ κ²°κ³Ό
- `models/metrics_lightgbm.json`: RMSE μµμ ν™” λ¨λΈ μ„±λ¥
- `models/metrics_ensemble.json`: μ•™μƒλΈ” λ¨λΈ μ„±λ¥
- `models/metrics_lightgbm_mae.json`: MAE μµμ ν™” λ¨λΈ μ„±λ¥ (μƒμ„± μ‹)

λλ” `src/compare_models.py`λ¥Ό μ‹¤ν–‰ν•μ—¬ μλ™ λΉ„κµ λ¦¬ν¬νΈ μƒμ„±:

```bash
python src/compare_models.py
```

---

## β οΈ μ£Όμμ‚¬ν•­

1. **λ°μ΄ν„° ν¬κΈ°**: μ „μ²΄ λ°μ΄ν„°μ…‹μ„ μ‚¬μ©ν•λ©΄ ν•μ΄νΌνλΌλ―Έν„° νλ‹μ— μ‹κ°„μ΄ μ¤λ κ±Έλ¦΄ μ μμµλ‹λ‹¤. μƒν” λ°μ΄ν„°λ΅ λ¨Όμ € ν…μ¤νΈν•λ” κ²ƒμ„ κ¶μ¥ν•©λ‹λ‹¤.

2. **λ©”λ¨λ¦¬ μ‚¬μ©**: μ•™μƒλΈ” λ¨λΈμ€ Random Forestμ™€ LightGBMμ„ λ¨λ‘ λ©”λ¨λ¦¬μ— λ΅λ“ν•λ―€λ΅ λ©”λ¨λ¦¬ μ‚¬μ©λ‰μ΄ μ¦κ°€ν•©λ‹λ‹¤.

3. **μ¬ν„μ„±**: λ¨λ“  λ¨λΈμ— `random_state=42`λ¥Ό μ„¤μ •ν•μ—¬ μ¬ν„ κ°€λ¥μ„±μ„ λ³΄μ¥ν–μµλ‹λ‹¤.

---

## π― λ‹¤μ λ‹¨κ³„

1. **κ°€κ²©λ€λ³„ λ¨λΈ λ¶„λ¦¬**: μ €κ°€/μ¤‘κ°€/κ³ κ°€ μ•„μ΄ν…λ³„λ΅ λ³„λ„ λ¨λΈ ν•™μµ
2. **μ‹κ³„μ—΄ νΉμ§• κ°•ν™”**: μ΄λ™ ν‰κ· , κ°€κ²© λ³€λ™λ¥  λ“± μ¶”κ°€
3. **λ”¥λ¬λ‹ λ¨λΈ μ‹λ„**: TabNet, TabTransformer λ“± ν…μ΄λΈ” λ°μ΄ν„°μ© λ”¥λ¬λ‹ λ¨λΈ
4. **μ‹¤μ‹κ°„ μμΈ΅ μ‹μ¤ν…**: API μ„λ²„ κµ¬μ¶• λ° μλ™ μ¬ν›λ ¨ νμ΄ν”„λΌμΈ

---

**μ‘μ„± μ™„λ£**: 2025-11-03


